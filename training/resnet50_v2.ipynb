{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937747e4-d104-4459-a995-6e6aad242b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a62cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Device/confirming it works with CUDA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "x = torch.randn(10000, 10000, device=device)\n",
    "print(\"Computation successful on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def subset_dataset(dataset, percent, seed=6050):\n",
    "    if percent >= 1.0:\n",
    "        return dataset\n",
    "    \n",
    "    random.seed(seed)\n",
    "    subset_size = int(len(dataset) * percent)\n",
    "    indices = random.sample(range(len(dataset)), subset_size)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "def plot_loss_and_acc(track_loss, track_train_acc, track_val_acc):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(track_loss, label=\"Loss\")\n",
    "    plt.plot(track_train_acc, label=\"Train\")\n",
    "    plt.plot(track_val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy/Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc109d97-e971-4e7c-9e36-dee12feeb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "\n",
    "data_root = Path(r\"C:/Users/Jimmy/OneDrive/Desktop/test/DS6050_Ai_Detection\")  # adjust as needed\n",
    "train_dir = data_root / \"train\"\n",
    "val_dir = data_root / \"validation\"\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-4\n",
    "train_percent = 0.5  # train/validate on 50% of data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68ee8d-3832-4ab2-8c20-737e8d869f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TRANSFORMS\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize for ResNet\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "'''\n",
    "resize will resize the image to 256x256\n",
    "randomcrop will random crop a 224x224 image from the 256x256 image\n",
    "randomhorizontalflip will randomly flip the image horizontally\n",
    "\n",
    "toTensor will convert the image to a tensor\n",
    "normalize will normalize the image, values are picked from imagenet mean and std, which the resnet50 is pretrained on\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253593ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader loads alphabetically, so we need to swap labels\n",
    "class CustomImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super().__getitem__(index)\n",
    "        # Swap label: make 'real' = 0, 'fake' = 1\n",
    "        label = 1 - label\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755ab48-2035-47b6-98b8-016faff2fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASETS\n",
    "\n",
    "train_dataset = CustomImageFolder(root=str(train_dir), transform=transform)\n",
    "val_dataset = CustomImageFolder(root=str(val_dir), transform=transform)\n",
    "\n",
    "print(\"Original class mapping:\", train_dataset.class_to_idx)  # still 'fake':0, 'real':1\n",
    "\n",
    "train_dataset = subset_dataset(train_dataset, train_percent)\n",
    "val_dataset = subset_dataset(val_dataset, train_percent)\n",
    "\n",
    "#DATALOADERS\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} images, validating on {len(val_dataset)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd25f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = train_dataset  # your Subset object\n",
    "\n",
    "# sample first 10 indices from the subset\n",
    "for idx in range(10):\n",
    "    actual_idx = subset.indices[idx]  # map to original dataset\n",
    "    img, label = subset[idx]\n",
    "    path = subset.dataset.imgs[actual_idx][0]  # original file path\n",
    "    print(f\"{path} --> Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4817b9b-9b54-44c1-bf31-3d6c6c296154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SETUP (ResNet50)\n",
    "\n",
    "model = models.resnet50(weights=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),   # hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, 2)           # final output\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # adding label smoothing for better generalization\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4) # adding L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d829d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SEED = 42\n",
    "# torch.manual_seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# random.seed(SEED)\n",
    "\n",
    "grid_size = 4\n",
    "num_images = grid_size * grid_size\n",
    "\n",
    "# Get all paths and labels\n",
    "all_paths = [p for p, l in val_dataset.dataset.samples] if isinstance(val_dataset, torch.utils.data.Subset) else [p for p, l in val_dataset.samples]\n",
    "all_labels = [l for p, l in val_dataset.dataset.samples] if isinstance(val_dataset, torch.utils.data.Subset) else [l for p, l in val_dataset.samples]\n",
    "\n",
    "labels_tensor = torch.tensor(all_labels)\n",
    "\n",
    "# Split real and fake indices\n",
    "real_indices = (labels_tensor == 0).nonzero(as_tuple=True)[0]\n",
    "fake_indices = (labels_tensor == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Take half from each class\n",
    "half_num = num_images // 2\n",
    "real_sample = real_indices[torch.randperm(len(real_indices))[:half_num]]\n",
    "fake_sample = fake_indices[torch.randperm(len(fake_indices))[:half_num]]\n",
    "\n",
    "subset_indices = torch.cat([real_sample, fake_sample])\n",
    "\n",
    "# Load images and labels\n",
    "fixed_images = torch.stack([val_dataset.dataset[i][0] for i in subset_indices]).to(device)\n",
    "fixed_labels = torch.tensor([val_dataset.dataset[i][1] for i in subset_indices]).to(device)\n",
    "fixed_paths = [all_paths[i] for i in subset_indices]\n",
    "\n",
    "# Visualize\n",
    "grid_img = make_grid(fixed_images.cpu(), nrow=grid_size, normalize=True)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.transpose(grid_img.numpy(), (1,2,0)))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fixed Validation Images\")\n",
    "plt.show()\n",
    "\n",
    "for path, lbl in zip(fixed_paths, fixed_labels):\n",
    "    print(f\"{'Real' if lbl==0 else 'Fake'}: {os.path.basename(path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23edd4-2eb9-42c9-95ce-61a057b81ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    best_val_acc = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    track_loss = []\n",
    "    track_train_acc = []\n",
    "    track_val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        print(f\"\\nðŸ”¹ Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Wrap train loader with tqdm\n",
    "        train_pbar = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
    "        for images, labels in train_pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "            avg_loss = running_loss / (len(train_loader) if len(train_loader) > 0 else 1)\n",
    "\n",
    "            # Live update progress bar\n",
    "            train_pbar.set_postfix({\n",
    "                \"Loss\": f\"{avg_loss:.4f}\",\n",
    "                \"Train Acc\": f\"{train_acc:.2f}%\"\n",
    "            })\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_pbar = tqdm(val_loader, desc=\"Validating\", unit=\"batch\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            #-------------images\n",
    "            outputs_grid = model(fixed_images)\n",
    "            preds_grid = torch.argmax(outputs_grid, dim=1)\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        label_names = ['Real', 'Fake']\n",
    "        true_names = [label_names[l.item()] for l in fixed_labels]\n",
    "        pred_names = [label_names[p.item()] for p in preds_grid]\n",
    "\n",
    "        # Create the figure\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(8, 8))\n",
    "\n",
    "        # --- Row 1: Image grid ---\n",
    "        grid_img = make_grid(fixed_images.cpu(), nrow=grid_size, normalize=True)\n",
    "        axs[0].imshow(np.transpose(grid_img.numpy(), (1, 2, 0)))\n",
    "        axs[0].set_title(\"Validation Samples\")\n",
    "        axs[0].axis(\"off\")\n",
    "\n",
    "        # Image dimensions for positioning labels\n",
    "        img_w = grid_img.shape[2] // grid_size\n",
    "        img_h = grid_img.shape[1] // grid_size\n",
    "\n",
    "        # --- Row 2: True labels (white background + text) ---\n",
    "        axs[1].imshow(np.ones((img_h * grid_size, img_w * grid_size, 3)))\n",
    "        axs[1].set_title(\"True Labels\")\n",
    "        axs[1].axis(\"off\")\n",
    "        for i, lbl in enumerate(true_names):\n",
    "            axs[1].text(\n",
    "                (i % grid_size + 0.5) * img_w,\n",
    "                (i // grid_size + 0.5) * img_h,\n",
    "                lbl,\n",
    "                ha='center', va='center', fontsize=14, color='black'\n",
    "            )\n",
    "\n",
    "        # --- Row 3: Predicted labels (green/red text for correctness) ---\n",
    "        axs[2].imshow(np.ones((img_h * grid_size, img_w * grid_size, 3)))\n",
    "        axs[2].set_title(\"Predicted Labels\")\n",
    "        axs[2].axis(\"off\")\n",
    "        for i, lbl in enumerate(pred_names):\n",
    "            color = 'green' if lbl == true_names[i] else 'red'\n",
    "            axs[2].text(\n",
    "                (i % grid_size + 0.5) * img_w,\n",
    "                (i // grid_size + 0.5) * img_h,\n",
    "                lbl,\n",
    "                ha='center', va='center', fontsize=14, color=color\n",
    "            )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_resnet50_v2.pth\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
    "              f\"Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        track_loss.append(avg_loss)\n",
    "        track_train_acc.append(train_acc)\n",
    "        track_val_acc.append(val_acc)\n",
    "\n",
    "    print(f\"\\nTraining complete in {(time.time() - start_time)/60:.2f} minutes.\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    plot_loss_and_acc(track_loss, track_train_acc, track_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d27933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "id_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
